# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434/v1

# Model Configuration
ROOT_MODEL=qwen3:14b
SUB_MODEL=qwen3:14b

# Execution Limits
MAX_ITERATIONS=20
MAX_OUTPUT_CHARS=10000
MAX_CONTEXT_CHARS_DISPLAY=500
EXECUTION_TIMEOUT=30

# LLM Settings
TEMPERATURE=0.7

# Debug Mode
DEBUG=false
